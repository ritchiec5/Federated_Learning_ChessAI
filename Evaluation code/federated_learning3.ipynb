{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukmA7z-dlB6m"
   },
   "source": [
    "# TensorFlow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6S7QNZqwmBOP"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.utils as utils\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "client1_model = tensorflow.keras.models.load_model(\n",
    "    'model_weight/global_model.h5')\n",
    "client2_model = tensorflow.keras.models.load_model(\n",
    "    'model_weight/global_model.h5')\n",
    "client3_model = tensorflow.keras.models.load_model(\n",
    "    'model_weight/global_model.h5')\n",
    "client4_model = tensorflow.keras.models.load_model(\n",
    "    'model_weight/global_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ck79-w2ZxwVB"
   },
   "source": [
    "# It's training time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "id": "CkOXxmoVyHdc"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "\tcontainer = numpy.load('dataset.npz') # Download dataset.npz from the link in Readme.md\n",
    "\tb, v = container['b'], container['v']\n",
    "\tv = numpy.asarray(v / abs(v).max() / 2 + 0.5, dtype=numpy.float32) # normalization (0 - 1)\n",
    "\treturn b, v\n",
    "\n",
    "x_train, y_train = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset for two clients\n",
    "# pip install -U scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "client1_x, client2_x, client1_y, client2y = train_test_split(x_train, y_train, test_size=0.50, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dellocate variable to save RAM space\n",
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client1_X, client2_X, client1_Y, client2_Y = train_test_split(\n",
    "    client1_x, client1_y, test_size=0.5, random_state=100)\n",
    "client3_X, client4_X, client3_Y, client4_Y = train_test_split(\n",
    "    client2_x, client2y, test_size=0.5, random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "165/165 [==============================] - 112s 681ms/step - loss: 2.8387e-04 - val_loss: 2.7435e-04\n",
      "Epoch 2/100\n",
      "165/165 [==============================] - 117s 707ms/step - loss: 2.8340e-04 - val_loss: 2.7467e-04\n",
      "Epoch 3/100\n",
      "165/165 [==============================] - 103s 626ms/step - loss: 2.8296e-04 - val_loss: 2.7471e-04\n",
      "Epoch 4/100\n",
      "165/165 [==============================] - 105s 634ms/step - loss: 2.8267e-04 - val_loss: 2.7491e-04\n",
      "Epoch 5/100\n",
      "165/165 [==============================] - 108s 654ms/step - loss: 2.8224e-04 - val_loss: 2.7513e-04\n",
      "Epoch 6/100\n",
      "165/165 [==============================] - 118s 715ms/step - loss: 2.8196e-04 - val_loss: 2.7499e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a990a0790>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training client 1 model\n",
    "\"\"\"\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "client1_model.fit(client1_X, client1_Y,\n",
    "          batch_size=2048,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RyOYq9mv2ppC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "165/165 [==============================] - 108s 648ms/step - loss: 2.8171e-04 - val_loss: 2.8550e-04\n",
      "Epoch 2/100\n",
      "165/165 [==============================] - 107s 651ms/step - loss: 2.8104e-04 - val_loss: 2.8613e-04\n",
      "Epoch 3/100\n",
      "165/165 [==============================] - 105s 639ms/step - loss: 2.8052e-04 - val_loss: 2.8608e-04\n",
      "Epoch 4/100\n",
      "165/165 [==============================] - 100s 605ms/step - loss: 2.8006e-04 - val_loss: 2.8605e-04\n",
      "Epoch 5/100\n",
      "165/165 [==============================] - 102s 619ms/step - loss: 2.7963e-04 - val_loss: 2.8598e-04\n",
      "Epoch 6/100\n",
      "165/165 [==============================] - 103s 624ms/step - loss: 2.7920e-04 - val_loss: 2.8656e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a990dd490>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training client 2 model\n",
    "\"\"\"\n",
    "\n",
    "client2_model.fit(client2_X, client2_Y,\n",
    "          batch_size=2048,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "165/165 [==============================] - 110s 661ms/step - loss: 2.8662e-04 - val_loss: 2.8329e-04\n",
      "Epoch 2/100\n",
      "165/165 [==============================] - 106s 644ms/step - loss: 2.8592e-04 - val_loss: 2.8370e-04\n",
      "Epoch 3/100\n",
      "165/165 [==============================] - 109s 664ms/step - loss: 2.8536e-04 - val_loss: 2.8385e-04\n",
      "Epoch 4/100\n",
      "165/165 [==============================] - 107s 652ms/step - loss: 2.8486e-04 - val_loss: 2.8398e-04\n",
      "Epoch 5/100\n",
      "165/165 [==============================] - 108s 652ms/step - loss: 2.8436e-04 - val_loss: 2.8432e-04\n",
      "Epoch 6/100\n",
      "165/165 [==============================] - 104s 633ms/step - loss: 2.8401e-04 - val_loss: 2.8449e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a9919cb20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training client 3 model\n",
    "\"\"\"\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "client3_model.fit(client3_X, client3_Y,\n",
    "          batch_size=2048,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "165/165 [==============================] - 109s 658ms/step - loss: 2.8385e-04 - val_loss: 2.8440e-04\n",
      "Epoch 2/100\n",
      "165/165 [==============================] - 109s 661ms/step - loss: 2.8322e-04 - val_loss: 2.8481e-04\n",
      "Epoch 3/100\n",
      "165/165 [==============================] - 107s 651ms/step - loss: 2.8260e-04 - val_loss: 2.8492e-04\n",
      "Epoch 4/100\n",
      "165/165 [==============================] - 110s 669ms/step - loss: 2.8213e-04 - val_loss: 2.8526e-04\n",
      "Epoch 5/100\n",
      "165/165 [==============================] - 107s 651ms/step - loss: 2.8176e-04 - val_loss: 2.8546e-04\n",
      "Epoch 6/100\n",
      "165/165 [==============================] - 106s 641ms/step - loss: 2.8131e-04 - val_loss: 2.8561e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a9a521520>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training client 4 model\n",
    "\"\"\"\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "client4_model = tensorflow.keras.models.load_model(\n",
    "    'model_weight/global_model.h5')\n",
    "client4_model.fit(client4_X, client4_Y,\n",
    "          batch_size=2048,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aggregrate models\n",
    "\"\"\"\n",
    "\n",
    "client1_weights = client1_model.get_weights()\n",
    "client2_weights = client2_model.get_weights()\n",
    "client3_weights = client3_model.get_weights()\n",
    "client4_weights = client4_model.get_weights()\n",
    "\n",
    "\n",
    "client1_weights = numpy.array(client1_weights, dtype=object)\n",
    "client2_weights = numpy.array(client2_weights, dtype=object)\n",
    "client3_weights = numpy.array(client3_weights, dtype=object)\n",
    "client4_weights = numpy.array(client4_weights, dtype=object)\n",
    "\n",
    "\n",
    "client1_weights = 1/4 * client1_weights\n",
    "client2_weights = 1/4 * client2_weights\n",
    "client3_weights = 1/4 * client3_weights\n",
    "client4_weights = 1/4 * client4_weights\n",
    "\n",
    "aggregated_weights = numpy.add(client1_weights,client2_weights)\n",
    "aggregated_weights = numpy.add(aggregated_weights, client3_weights)\n",
    "aggregated_weights = numpy.add(aggregated_weights, client4_weights)\n",
    "\n",
    "client1_model.set_weights(aggregated_weights)\n",
    "client1_model.save_weights(\"model_weight/federated3_weights\", save_format=\"h5\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Chess AI",
   "private_outputs": true,
   "provenance": []
  },
  "interpreter": {
   "hash": "7e7666bfb430d4514d1195031d15ccf80594a969647ade4f9e6074d5049c6fab"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
