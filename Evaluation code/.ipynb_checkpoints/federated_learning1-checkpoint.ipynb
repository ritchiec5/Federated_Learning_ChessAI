{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukmA7z-dlB6m"
   },
   "source": [
    "# TensorFlow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6S7QNZqwmBOP"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.utils as utils\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "client1_model = tensorflow.keras.models.load_model(\n",
    "    'model_weight/global_model.h5')\n",
    "client2_model = tensorflow.keras.models.load_model(\n",
    "    'model_weight/global_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ck79-w2ZxwVB"
   },
   "source": [
    "# It's training time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "id": "CkOXxmoVyHdc"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "\tcontainer = numpy.load('dataset.npz') # Download dataset.npz from the link in Readme.md\n",
    "\tb, v = container['b'], container['v']\n",
    "\tv = numpy.asarray(v / abs(v).max() / 2 + 0.5, dtype=numpy.float32) # normalization (0 - 1)\n",
    "\treturn b, v\n",
    "\n",
    "x_train, y_train = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset for two clients\n",
    "# pip install -U scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "client1_x, client2_x, client1_y, client2y =train_test_split(x_train, y_train, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "214/330 [==================>...........] - ETA: 46s - loss: 2.8326e-04"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training client 1 model\n",
    "\"\"\"\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_filepath = '/checkpoint/f1-1/'\n",
    "model_checkpointing_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only=True,\n",
    ")\n",
    "client1_model.fit(client1_x, client1_y,\n",
    "          batch_size=2048,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4), model_checkpointing_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RyOYq9mv2ppC"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training client 2 model\n",
    "\"\"\"\n",
    "checkpoint_filepath = '/tmp/checkpoint/f1-2/'\n",
    "model_checkpointing_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only=True,\n",
    ")\n",
    "client2_model.fit(client2_x, client2y,\n",
    "          batch_size=2048,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4), model_checkpointing_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aggregrate models\n",
    "\"\"\"\n",
    "\n",
    "client1_weights = client1_model.get_weights()\n",
    "client2_weights = client2_model.get_weights()\n",
    "\n",
    "client1_weights = numpy.array(client1_weights, dtype=object)\n",
    "client2_weights = numpy.array(client2_weights, dtype=object)\n",
    "\n",
    "client1_weights = 1/2 * client1_weights\n",
    "client2_weights = 1/2 * client2_weights\n",
    "\n",
    "aggregated_weights = numpy.add(client1_weights,client2_weights)\n",
    "\n",
    "client1_model.set_weights(aggregated_weights)\n",
    "client2_model.save_weights(\"model_weight/federated1_weights\", save_format=\"h5\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Chess AI",
   "private_outputs": true,
   "provenance": []
  },
  "interpreter": {
   "hash": "7e7666bfb430d4514d1195031d15ccf80594a969647ade4f9e6074d5049c6fab"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
