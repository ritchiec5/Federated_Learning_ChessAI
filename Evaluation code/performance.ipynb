{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy\n",
    "\n",
    "squares_index = {\n",
    "    'a': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'd': 3,\n",
    "    'e': 4,\n",
    "    'f': 5,\n",
    "    'g': 6,\n",
    "    'h': 7\n",
    "}\n",
    "\n",
    "\n",
    "# example: h3 -> 17\n",
    "def square_to_index(square):\n",
    "  letter = chess.square_name(square)\n",
    "  return 8 - int(letter[1]), squares_index[letter[0]]\n",
    "\n",
    "\n",
    "def split_dims(board):\n",
    "  # this is the 3d matrix\n",
    "  board3d = numpy.zeros((14, 8, 8), dtype=numpy.int8)\n",
    "\n",
    "  # here we add the pieces's view on the matrix\n",
    "  for piece in chess.PIECE_TYPES:\n",
    "    for square in board.pieces(piece, chess.WHITE):\n",
    "      idx = numpy.unravel_index(square, (8, 8))\n",
    "      board3d[piece - 1][7 - idx[0]][idx[1]] = 1\n",
    "    for square in board.pieces(piece, chess.BLACK):\n",
    "      idx = numpy.unravel_index(square, (8, 8))\n",
    "      board3d[piece + 5][7 - idx[0]][idx[1]] = 1\n",
    "\n",
    "  # add attacks and valid moves too\n",
    "  # so the network knows what is being attacked\n",
    "  aux = board.turn\n",
    "  board.turn = chess.WHITE\n",
    "  for move in board.legal_moves:\n",
    "      i, j = square_to_index(move.to_square)\n",
    "      board3d[12][i][j] = 1\n",
    "  board.turn = chess.BLACK\n",
    "  for move in board.legal_moves:\n",
    "      i, j = square_to_index(move.to_square)\n",
    "      board3d[13][i][j] = 1\n",
    "  board.turn = aux\n",
    "\n",
    "  return board3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "\t# Download dataset.npz from the link in Readme.md\n",
    "\tcontainer = numpy.load('dataset.npz')\n",
    "\tb, v = container['b'], container['v']\n",
    "\tv = numpy.asarray(v / abs(v).max() / 2 + 0.5,\n",
    "\t                  dtype=numpy.float32)  # normalization (0 - 1)\n",
    "\treturn b, v\n",
    "\n",
    "\n",
    "x_train, y_train = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset for two clients\n",
    "# pip install -U scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, y_train, x_test, y_test = train_test_split(\n",
    "    x_train, y_train, test_size=0.9, random_state=100)\n",
    "x_train, y_train, x_test, y_test = train_test_split(\n",
    "    x_train, y_train, test_size=0.3, random_state=100)\n",
    "fed_x_train, fed_y_train, x_test, y_test = train_test_split(\n",
    "    x_test, y_test, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.utils as utils\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "\n",
    "def build_model(conv_size, conv_depth):\n",
    "  board3d = layers.Input(shape=(14, 8, 8))\n",
    "\n",
    "  # adding the convolutional layers\n",
    "  x = board3d\n",
    "  for _ in range(conv_depth):\n",
    "    x = layers.Conv2D(filters=conv_size, kernel_size=3,\n",
    "                      padding='same', activation='relu')(x)\n",
    "  x = layers.Flatten()(x)\n",
    "  x = layers.Dense(64, 'relu')(x)\n",
    "  x = layers.Dense(1, 'sigmoid')(x)\n",
    "\n",
    "  return models.Model(inputs=board3d, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(32, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=2048,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n",
    "\n",
    "model.save_weights(\"model_weight/new_cen_weights\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed1 = model\n",
    "fed2 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed1.fit(x_train, y_train,\n",
    "          batch_size=2048,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed2.fit(x_train, y_train,\n",
    "          batch_size=2048,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed1_weights = fed1.get_weights()\n",
    "fed2_weights = fed2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client1_weights = numpy.array(fed1_weights, dtype=object)\n",
    "client2_weights = numpy.array(fed2_weights, dtype=object)\n",
    "aggregated_weights = numpy.add(client1_weights,client2_weights)\n",
    "fed1.set_weights(aggregated_weights)\n",
    "fed1.save_weights(\"model_weight/new_fed_weights\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result0 = model.evaluate(x_test, y_test, batch_size = 32)\n",
    "print(\"test loss, test acc:\", result0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = fed1.evaluate(x_test, y_test, batch_size = 32)\n",
    "print(\"test loss, test acc:\", result1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
