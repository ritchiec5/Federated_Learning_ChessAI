{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy\n",
    "\n",
    "squares_index = {\n",
    "    'a': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'd': 3,\n",
    "    'e': 4,\n",
    "    'f': 5,\n",
    "    'g': 6,\n",
    "    'h': 7\n",
    "}\n",
    "\n",
    "\n",
    "# example: h3 -> 17\n",
    "def square_to_index(square):\n",
    "  letter = chess.square_name(square)\n",
    "  return 8 - int(letter[1]), squares_index[letter[0]]\n",
    "\n",
    "\n",
    "def split_dims(board):\n",
    "  # this is the 3d matrix\n",
    "  board3d = numpy.zeros((14, 8, 8), dtype=numpy.int8)\n",
    "\n",
    "  # here we add the pieces's view on the matrix\n",
    "  for piece in chess.PIECE_TYPES:\n",
    "    for square in board.pieces(piece, chess.WHITE):\n",
    "      idx = numpy.unravel_index(square, (8, 8))\n",
    "      board3d[piece - 1][7 - idx[0]][idx[1]] = 1\n",
    "    for square in board.pieces(piece, chess.BLACK):\n",
    "      idx = numpy.unravel_index(square, (8, 8))\n",
    "      board3d[piece + 5][7 - idx[0]][idx[1]] = 1\n",
    "\n",
    "  # add attacks and valid moves too\n",
    "  # so the network knows what is being attacked\n",
    "  aux = board.turn\n",
    "  board.turn = chess.WHITE\n",
    "  for move in board.legal_moves:\n",
    "      i, j = square_to_index(move.to_square)\n",
    "      board3d[12][i][j] = 1\n",
    "  board.turn = chess.BLACK\n",
    "  for move in board.legal_moves:\n",
    "      i, j = square_to_index(move.to_square)\n",
    "      board3d[13][i][j] = 1\n",
    "  board.turn = aux\n",
    "\n",
    "  return board3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "\t# Download dataset.npz from the link in Readme.md\n",
    "\tcontainer = numpy.load('dataset.npz')\n",
    "\tb, v = container['b'], container['v']\n",
    "\tv = numpy.asarray(v / abs(v).max() / 2 + 0.5,\n",
    "\t                  dtype=numpy.float32)  # normalization (0 - 1)\n",
    "\treturn b, v\n",
    "\n",
    "\n",
    "x_train, y_train = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset for two clients\n",
    "# pip install -U scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_train, y_train, test_size=0.1, random_state=100)\n",
    "\n",
    "# Initial Model Dataset\n",
    "x_train, x_train1, y_train, y_train2 = train_test_split(\n",
    "    x_test, y_test, test_size=0.3, random_state=100)\n",
    "\n",
    "# Client Dataset\n",
    "fed_x_train, x_test, fed_y_train, y_test = train_test_split(\n",
    "    x_train, y_train, test_size=0.1, random_state=100)\n",
    "\n",
    "fed_x_train, x_test, fed_y_train, y_test = train_test_split(\n",
    "    x_test, y_test, test_size=0.3, random_state=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.utils as utils\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "\n",
    "def build_model(conv_size, conv_depth):\n",
    "  board3d = layers.Input(shape=(14, 8, 8))\n",
    "\n",
    "  # adding the convolutional layers\n",
    "  x = board3d\n",
    "  for _ in range(conv_depth):\n",
    "    x = layers.Conv2D(filters=conv_size, kernel_size=3,\n",
    "                      padding='same', activation='relu')(x)\n",
    "  x = layers.Flatten()(x)\n",
    "  x = layers.Dense(64, 'relu')(x)\n",
    "  x = layers.Dense(1, 'sigmoid')(x)\n",
    "\n",
    "  return models.Model(inputs=board3d, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(32, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 12s 548ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 12s 613ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 12s 582ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 11s 574ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 12s 575ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 11s 561ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 11s 567ms/step - loss: 9.8327e-04 - val_loss: 9.8444e-04\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 12s 592ms/step - loss: 8.4499e-04 - val_loss: 9.9065e-04\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 12s 608ms/step - loss: 7.8376e-04 - val_loss: 8.4580e-04\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 12s 591ms/step - loss: 8.2823e-04 - val_loss: 8.3569e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "# model.summary()\n",
    "\n",
    "model.fit(x_train1, y_train2,\n",
    "          batch_size=2048,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n",
    "\n",
    "model.save_weights(\"model_weight/new_cen_weights\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed1 = model\n",
    "fed2 = model\n",
    "fed3 = model\n",
    "fed4 = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 8.1111e-04 - val_loss: 8.1854e-04\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 7.9241e-04 - val_loss: 8.0635e-04\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 7.7386e-04 - val_loss: 8.0086e-04\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 7.6296e-04 - val_loss: 7.9226e-04\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 7.5847e-04 - val_loss: 7.9331e-04\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 7.4657e-04 - val_loss: 7.8254e-04\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 7.2781e-04 - val_loss: 7.9965e-04\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 7.2737e-04 - val_loss: 7.8613e-04\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 2s 591ms/step - loss: 7.1956e-04 - val_loss: 7.9686e-04\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 7.1254e-04 - val_loss: 7.7829e-04\n"
     ]
    }
   ],
   "source": [
    "fed1.load_weights(\"model_weight/new_cen_weights\")\n",
    "fed1.fit(fed_x_train, fed_y_train,\n",
    "          batch_size=2048,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n",
    "\n",
    "fed1_weights = fed1.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 2s 510ms/step - loss: 8.1053e-04 - val_loss: 6.8932e-04\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 2s 498ms/step - loss: 7.8033e-04 - val_loss: 6.9031e-04\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 2s 494ms/step - loss: 7.7288e-04 - val_loss: 6.7804e-04\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 2s 501ms/step - loss: 7.5032e-04 - val_loss: 6.7530e-04\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 2s 559ms/step - loss: 7.4752e-04 - val_loss: 6.6582e-04\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 2s 534ms/step - loss: 7.3102e-04 - val_loss: 6.5670e-04\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 3s 621ms/step - loss: 7.1383e-04 - val_loss: 6.5210e-04\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 2s 555ms/step - loss: 7.0273e-04 - val_loss: 6.5218e-04\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 2s 565ms/step - loss: 6.9372e-04 - val_loss: 6.4856e-04\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 2s 558ms/step - loss: 6.9437e-04 - val_loss: 6.4867e-04\n"
     ]
    }
   ],
   "source": [
    "fed2.load_weights(\"model_weight/new_cen_weights\")\n",
    "fed2.fit(fed_x_train, fed_y_train,\n",
    "          batch_size=2048,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n",
    "fed2_weights = fed2.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "client1_weights = numpy.array(fed1_weights, dtype=object)\n",
    "client2_weights = numpy.array(fed2_weights, dtype=object)\n",
    "client1_weights = 1/2 * client1_weights\n",
    "client2_weights = 1/2 * client2_weights\n",
    "aggregated_weights = numpy.add(client1_weights,client2_weights)\n",
    "\n",
    "fed1.set_weights(aggregated_weights)\n",
    "fed1.save_weights(\"model_weight/new_fed_weights\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 14s 688ms/step - loss: 7.1649e-04 - val_loss: 8.0116e-04\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 13s 653ms/step - loss: 6.9262e-04 - val_loss: 7.9037e-04\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 13s 661ms/step - loss: 6.7489e-04 - val_loss: 7.5290e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 13s 635ms/step - loss: 6.5606e-04 - val_loss: 7.4143e-04\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 13s 639ms/step - loss: 6.4952e-04 - val_loss: 7.2545e-04\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 12s 623ms/step - loss: 6.4547e-04 - val_loss: 7.1558e-04\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 13s 629ms/step - loss: 6.2870e-04 - val_loss: 7.4997e-04\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 12s 624ms/step - loss: 6.3702e-04 - val_loss: 7.6081e-04\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 13s 643ms/step - loss: 6.2092e-04 - val_loss: 6.8659e-04\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 13s 629ms/step - loss: 6.0716e-04 - val_loss: 6.7247e-04\n"
     ]
    }
   ],
   "source": [
    "fed3.load_weights(\"model_weight/new_cen_weights\")\n",
    "fed3.fit(x_train1, y_train2,\n",
    "         batch_size=2048,\n",
    "         epochs=10,\n",
    "         verbose=1,\n",
    "         validation_split=0.1,\n",
    "         callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                    callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n",
    "fed3_weights = fed3.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 13s 678ms/step - loss: 7.2012e-04 - val_loss: 7.8901e-04\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 14s 685ms/step - loss: 6.8037e-04 - val_loss: 7.7008e-04\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 14s 683ms/step - loss: 6.6813e-04 - val_loss: 7.7182e-04\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 13s 643ms/step - loss: 6.6281e-04 - val_loss: 7.6087e-04\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 13s 670ms/step - loss: 6.6817e-04 - val_loss: 7.2299e-04\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 13s 648ms/step - loss: 6.3937e-04 - val_loss: 7.8590e-04\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 13s 651ms/step - loss: 6.3142e-04 - val_loss: 7.1532e-04\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 13s 643ms/step - loss: 6.3915e-04 - val_loss: 7.0222e-04\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 13s 648ms/step - loss: 6.1232e-04 - val_loss: 6.8025e-04\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 13s 652ms/step - loss: 5.9473e-04 - val_loss: 6.8381e-04\n"
     ]
    }
   ],
   "source": [
    "fed4.load_weights(\"model_weight/new_cen_weights\")\n",
    "fed4.fit(x_train1, y_train2,\n",
    "         batch_size=2048,\n",
    "         epochs=10,\n",
    "         verbose=1,\n",
    "         validation_split=0.1,\n",
    "         callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                    callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n",
    "fed4_weights = fed4.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed3_weights = fed3.get_weights()\n",
    "fed4_weights = fed4.get_weights()\n",
    "client1_weights = numpy.array(fed3_weights, dtype=object)\n",
    "client2_weights = numpy.array(fed4_weights, dtype=object)\n",
    "client1_weights = 1/2 * client1_weights\n",
    "client2_weights = 1/2 * client2_weights\n",
    "aggregated_weights = numpy.add(client1_weights, client2_weights)\n",
    "fed3.set_weights(aggregated_weights)\n",
    "fed3.save_weights(\"model_weight/new_fed1_weights\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 4ms/step - loss: 8.1669e-04\n",
      "test loss, test acc: 0.000816692307125777\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"model_weight/new_cen_weights\")\n",
    "result0 = model.evaluate(x_test, y_test, batch_size = 32)\n",
    "print(\"test loss, test acc:\", result0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 4ms/step - loss: 7.6132e-04\n",
      "test loss, test acc: 0.0007613188354298472\n"
     ]
    }
   ],
   "source": [
    "fed1.load_weights(\"model_weight/new_fed_weights\")\n",
    "result1 = fed1.evaluate(x_test, y_test, batch_size = 32)\n",
    "print(\"test loss, test acc:\", result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 4ms/step - loss: 7.1827e-04\n",
      "test loss, test acc: 0.0007182715344242752\n"
     ]
    }
   ],
   "source": [
    "fed3.load_weights(\"model_weight/new_fed1_weights\")\n",
    "result1 = fed3.evaluate(x_test, y_test, batch_size=32)\n",
    "print(\"test loss, test acc:\", result1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e7666bfb430d4514d1195031d15ccf80594a969647ade4f9e6074d5049c6fab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
