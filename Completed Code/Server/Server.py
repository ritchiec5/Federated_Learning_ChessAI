import os
import threading
from flask import Flask, request, jsonify, send_file
import requests
import numpy
import tensorflow
app = Flask(__name__)

FILEPATH = os.path.abspath("Completed Code\Server")

# Global Variable for Model Aggregation
client_weights_filepath_list = []   # Contains Array of Client Weights filepath
global_dataset_size = 0             # Contains Sum of client dataset size
client_dataset_size_list = []       # Contains Array of client dataset size

"""
send_global_weights():
    Sends global model data when client sends GET request
"""
@app.route('/server/send_global_weights', methods=['GET'])
def send_global_weights():
    if request.method == 'GET':  # Client has just initialzed and is requesting model data
        print("Sending Global Weights")
        filepath = FILEPATH + "\\model_data\\global_model.h5"
        print(filepath)
        return send_file(filepath)

"""
receive_client_weights():
    1. Receive clients weights when client send POST request
    2. Save client weights into a file
    3. Initialize Aggregation via threading 
"""
@app.route('/server/receive_client_weights', methods=['POST'])
def receive_client_weights():
    global global_dataset_size
    global client_dataset_size_list
    
    if request.method == 'POST': 
        # Save weights into a file
        client_id = request.args.get("client")
        client_dataset_size = request.args.get("datasize")
        filename = FILEPATH + "\\model_data\\client_weight{}".format(client_id)
        with open(filename, "wb") as f:
            f.write(request.data)
        f.close()

        # Update variables for Aggregation
        client_dataset_size_list.append(int(client_dataset_size))
        global_dataset_size = global_dataset_size + int(client_dataset_size)
        client_weights_filepath_list.append(filename)

        # Initialize aggregation
        aggregation_thread = threading.Thread(target=aggregation)
        aggregation_thread.start()
        return jsonify("Client weights received")

"""
aggregation():
    1. aggregate client weights into update global weight
    2. sends client updated weights 
"""
def aggregation():
    # Model initialization
    model = tensorflow.keras.models.load_model(FILEPATH + "\\model_data\\global_model.h5")

    # Model Aggregation
    print("Aggregating client weights")
    weight_scaling_factor_list = weight_scaling_factor() # Find client dataset contribution scale of 0 to 1
    scaled_client_weights = scale_model_weight(weight_scaling_factor_list, model) # Scale client model weight by client dataset contribution scale
    sum_scaled_weights(scaled_client_weights, model) # Sum scaled client model weights
    
    print("Model Aggregated")
    # Send clients updated weights
    send_client_updated_weights()

"""
weight_scaling_factor():
    Finds client dataset contribution by "Client dataset size / Global dataset size".
    - Global dataset size refers to the sum of client dataset

Returns:
    weight_scaling_factor_list: Array of client dataset contribution (AKA weight scaling factor) on a scale of 0 to 1
"""
def weight_scaling_factor():
    global global_dataset_size
    print(client_dataset_size_list)
    
    weight_scaling_factor_list = [
        client_datasize / global_dataset_size for client_datasize in client_dataset_size_list]
    print(weight_scaling_factor_list)
    return weight_scaling_factor_list

"""
scale_model_weight():
    scale the model weights by "model weight * weight scaling factor"

parameters:
    - weight_scaling_factor_list: Array of weight scaling factor
    - model: Tensorflow AI model

Returns:
    scaled_client_weights: Array of scaled client weights 
"""
def scale_model_weight(weight_scaling_factor_list, model):
    scaled_client_weights = []
    print(client_weights_filepath_list)
    for i, scaling_factor in enumerate(weight_scaling_factor_list):
        print(i)
        filepath = client_weights_filepath_list[int(i)]
        model.load_weights(filepath)
        client_weight = model.get_weights()
        client_weight = numpy.array(client_weight, dtype='object')
        scaled_client_weights.append(client_weight * scaling_factor)
    return scaled_client_weights

"""
sum_scaled_weights():
    1. Summation of scaled model weights by "sum(model weight)"
    2. Saved aggregated weights into a file

parameters:
    - scaled_client_weights: Array of scaled client weights 
    - model: Tensorflow AI model
"""
def sum_scaled_weights(scaled_client_weights, model):
    global_weight = scaled_client_weights[0]
    for client_weight in scaled_client_weights[1:]:
        global_weight = numpy.add(global_weight, client_weight)
    model.set_weights(global_weight)
    model.save_weights(
        FILEPATH + "\\model_data\\Updated_global_weights", save_format="h5")

"""
send_client_updated_weights()
    send client the updated global weights from the aggregation
"""
def send_client_updated_weights():
    print("Sending updated global weights")
    file = open(FILEPATH + "\\model_data\\Updated_global_weights", "rb")
    res = requests.post(
        'http://localhost:5001/client/receive_global_weights', file)
    print(res.text)

if __name__ == '__main__':
    app.run(port=5000, debug=False)
